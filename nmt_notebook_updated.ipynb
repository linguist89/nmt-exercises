{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e54436",
   "metadata": {},
   "source": [
    "# Neural Machine Translation: English to French\n",
    "\n",
    "This notebook demonstrates the evaluation of different English to French translation models using multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ad936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets evaluate sacrebleu\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install sentencepiece\n",
    "!pip install sacremoses\n",
    "!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896faec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import evaluate\n",
    "from evaluate import load\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0aecc0",
   "metadata": {},
   "source": [
    "## Section 1: Dataset and Models\n",
    "\n",
    "In this section, we'll:\n",
    "1. Create a dataset of 50 English sentences\n",
    "2. Load 3 different English to French translation models\n",
    "3. Generate translations for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709dacd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our dataset of 50 English sentences\n",
    "english_sentences = [\n",
    "    \"The cat is sleeping on the windowsill.\",\n",
    "    \"I love to read books in the evening.\",\n",
    "    \"The weather is beautiful today.\",\n",
    "    \"She works at a local restaurant.\",\n",
    "    \"We are going to the park tomorrow.\",\n",
    "    \"The movie was very interesting.\",\n",
    "    \"He speaks French fluently.\",\n",
    "    \"The children are playing in the garden.\",\n",
    "    \"I need to buy some groceries.\",\n",
    "    \"The train arrives at 3 PM.\",\n",
    "    \"She likes to drink coffee in the morning.\",\n",
    "    \"The museum is closed on Mondays.\",\n",
    "    \"We visited Paris last summer.\",\n",
    "    \"The book is on the table.\",\n",
    "    \"He plays the piano very well.\",\n",
    "    \"The restaurant serves delicious food.\",\n",
    "    \"I want to learn a new language.\",\n",
    "    \"The sun is setting behind the mountains.\",\n",
    "    \"She writes beautiful poetry.\",\n",
    "    \"We need to clean the house.\",\n",
    "    \"The dog is barking at the mailman.\",\n",
    "    \"I enjoy listening to classical music.\",\n",
    "    \"The store opens at 9 AM.\",\n",
    "    \"He is studying for his exams.\",\n",
    "    \"The flowers are blooming in spring.\",\n",
    "    \"She drives to work every day.\",\n",
    "    \"We watched a movie last night.\",\n",
    "    \"The birds are singing in the trees.\",\n",
    "    \"I need to make a phone call.\",\n",
    "    \"The library is quiet and peaceful.\",\n",
    "    \"He likes to cook Italian food.\",\n",
    "    \"The beach is crowded in summer.\",\n",
    "    \"She is learning to swim.\",\n",
    "    \"We went shopping yesterday.\",\n",
    "    \"The clock is ticking on the wall.\",\n",
    "    \"I enjoy taking long walks.\",\n",
    "    \"The museum has many paintings.\",\n",
    "    \"He plays soccer with his friends.\",\n",
    "    \"The restaurant is full of customers.\",\n",
    "    \"She reads the newspaper every morning.\",\n",
    "    \"We need to fix the computer.\",\n",
    "    \"The cat is chasing a mouse.\",\n",
    "    \"I want to visit the zoo.\",\n",
    "    \"The garden needs watering.\",\n",
    "    \"He speaks three languages.\",\n",
    "    \"The movie starts at 7 PM.\",\n",
    "    \"She likes to dance ballet.\",\n",
    "    \"We are planning a vacation.\",\n",
    "    \"The birds are flying south.\",\n",
    "    \"I need to buy new shoes.\"\n",
    "]\n",
    "\n",
    "# Create reference French translations\n",
    "french_references = [\n",
    "    \"Le chat dort sur le rebord de la fenêtre.\",\n",
    "    \"J'aime lire des livres le soir.\",\n",
    "    \"Le temps est beau aujourd'hui.\",\n",
    "    \"Elle travaille dans un restaurant local.\",\n",
    "    \"Nous allons au parc demain.\",\n",
    "    \"Le film était très intéressant.\",\n",
    "    \"Il parle couramment le français.\",\n",
    "    \"Les enfants jouent dans le jardin.\",\n",
    "    \"J'ai besoin d'acheter des provisions.\",\n",
    "    \"Le train arrive à 15h.\",\n",
    "    \"Elle aime boire du café le matin.\",\n",
    "    \"Le musée est fermé le lundi.\",\n",
    "    \"Nous avons visité Paris l'été dernier.\",\n",
    "    \"Le livre est sur la table.\",\n",
    "    \"Il joue très bien du piano.\",\n",
    "    \"Le restaurant sert une délicieuse nourriture.\",\n",
    "    \"Je veux apprendre une nouvelle langue.\",\n",
    "    \"Le soleil se couche derrière les montagnes.\",\n",
    "    \"Elle écrit de la belle poésie.\",\n",
    "    \"Nous devons nettoyer la maison.\",\n",
    "    \"Le chien aboie contre le facteur.\",\n",
    "    \"J'aime écouter de la musique classique.\",\n",
    "    \"Le magasin ouvre à 9h.\",\n",
    "    \"Il étudie pour ses examens.\",\n",
    "    \"Les fleurs fleurissent au printemps.\",\n",
    "    \"Elle conduit au travail tous les jours.\",\n",
    "    \"Nous avons regardé un film hier soir.\",\n",
    "    \"Les oiseaux chantent dans les arbres.\",\n",
    "    \"Je dois faire un appel téléphonique.\",\n",
    "    \"La bibliothèque est calme et paisible.\",\n",
    "    \"Il aime cuisiner des plats italiens.\",\n",
    "    \"La plage est bondée en été.\",\n",
    "    \"Elle apprend à nager.\",\n",
    "    \"Nous sommes allés faire des courses hier.\",\n",
    "    \"L'horloge tic-tac sur le mur.\",\n",
    "    \"J'aime faire de longues promenades.\",\n",
    "    \"Le musée a beaucoup de tableaux.\",\n",
    "    \"Il joue au football avec ses amis.\",\n",
    "    \"Le restaurant est plein de clients.\",\n",
    "    \"Elle lit le journal tous les matins.\",\n",
    "    \"Nous devons réparer l'ordinateur.\",\n",
    "    \"Le chat poursuit une souris.\",\n",
    "    \"Je veux visiter le zoo.\",\n",
    "    \"Le jardin a besoin d'être arrosé.\",\n",
    "    \"Il parle trois langues.\",\n",
    "    \"Le film commence à 19h.\",\n",
    "    \"Elle aime danser le ballet.\",\n",
    "    \"Nous planifions des vacances.\",\n",
    "    \"Les oiseaux migrent vers le sud.\",\n",
    "    \"J'ai besoin d'acheter de nouvelles chaussures.\"\n",
    "]\n",
    "\n",
    "print(f\"Dataset size: {len(english_sentences)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61195fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load three different translation models\n",
    "model1 = pipeline(\"translation_en_to_fr\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "model2 = pipeline(\"translation_en_to_fr\", model=\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "model3 = pipeline(\"translation_en_to_fr\", model=\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate sentences using a model\n",
    "def translate_sentences(model, sentences):\n",
    "    translations = []\n",
    "    for sentence in sentences:\n",
    "        translated_text = model(sentence)[0]['translation_text']\n",
    "        translations.append(translated_text)\n",
    "    return translations\n",
    "\n",
    "# Generate translations using all three models\n",
    "translations_model1 = translate_sentences(model1, english_sentences)\n",
    "translations_model2 = translate_sentences(model2, english_sentences)\n",
    "translations_model3 = translate_sentences(model3, english_sentences)\n",
    "\n",
    "print(\"Translations completed for all three models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b1715",
   "metadata": {},
   "source": [
    "## Section 2: SACREBLEU Evaluation\n",
    "\n",
    "In this section, we'll evaluate the translations using the SACREBLEU metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SACREBLEU metric\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "# Calculate BLEU scores for each model\n",
    "bleu_score1 = bleu_metric.compute(predictions=translations_model1, references=[french_references])\n",
    "bleu_score2 = bleu_metric.compute(predictions=translations_model2, references=[french_references])\n",
    "bleu_score3 = bleu_metric.compute(predictions=translations_model3, references=[french_references])\n",
    "\n",
    "print(\"SACREBLEU Scores:\")\n",
    "print(f\"Model 1 (Helsinki-NLP): {bleu_score1['score']:.2f}\")\n",
    "print(f\"Model 2 (mBART): {bleu_score2['score']:.2f}\")\n",
    "print(f\"Model 3 (T5): {bleu_score3['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5527c1cb",
   "metadata": {},
   "source": [
    "## Section 3: BERTScore Evaluation\n",
    "\n",
    "In this section, we'll evaluate the translations using the BERTScore metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22512ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERTScore metric\n",
    "bert_metric = load(\"bertscore\")\n",
    "\n",
    "# Calculate BERTScore for each model\n",
    "bert_results1 = bert_metric.compute(predictions=translations_model1, references=french_references, lang=\"fr\")\n",
    "bert_results2 = bert_metric.compute(predictions=translations_model2, references=french_references, lang=\"fr\")\n",
    "bert_results3 = bert_metric.compute(predictions=translations_model3, references=french_references, lang=\"fr\")\n",
    "\n",
    "# Calculate average F1 scores\n",
    "avg_f1_1 = sum(bert_results1['f1']) / len(bert_results1['f1'])\n",
    "avg_f1_2 = sum(bert_results2['f1']) / len(bert_results2['f1'])\n",
    "avg_f1_3 = sum(bert_results3['f1']) / len(bert_results3['f1'])\n",
    "\n",
    "print(\"BERTScore F1 Scores:\")\n",
    "print(f\"Model 1 (Helsinki-NLP): {avg_f1_1:.4f}\")\n",
    "print(f\"Model 2 (mBART): {avg_f1_2:.4f}\")\n",
    "print(f\"Model 3 (T5): {avg_f1_3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a65599",
   "metadata": {},
   "source": [
    "## Section 4: Visualization\n",
    "\n",
    "In this section, we'll create visualizations to compare the performance of the three models using both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize BLEU scores to 0-1 range for comparison\n",
    "bleu1_norm = bleu_score1['score'] / 100\n",
    "bleu2_norm = bleu_score2['score'] / 100\n",
    "bleu3_norm = bleu_score3['score'] / 100\n",
    "\n",
    "# Set up the comparison data\n",
    "models = ['Helsinki-NLP', 'mBART', 'T5']\n",
    "bleu_scores = [bleu1_norm, bleu2_norm, bleu3_norm]\n",
    "bert_scores = [avg_f1_1, avg_f1_2, avg_f1_3]\n",
    "\n",
    "# Set width of bars\n",
    "barWidth = 0.3\n",
    "r1 = np.arange(len(models))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "# Create the bars\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(r1, bleu_scores, width=barWidth, label='SACREBLEU (normalized)')\n",
    "plt.bar(r2, bert_scores, width=barWidth, label='BERTScore F1')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Translation Models')\n",
    "plt.ylabel('Score (0-1 scale)')\n",
    "plt.title('Comparison of Translation Models using SACREBLEU and BERTScore')\n",
    "plt.xticks([r + barWidth/2 for r in range(len(models))], models)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec59987c",
   "metadata": {},
   "source": [
    "### Analysis of Results\n",
    "\n",
    "The visualization shows the performance of three different translation models evaluated using both SACREBLEU and BERTScore metrics:\n",
    "\n",
    "1. **SACREBLEU Scores**:\n",
    "   - Measures exact word matches between translations and references\n",
    "   - Higher scores indicate more word-level accuracy\n",
    "   - Normalized to 0-1 scale for easier comparison\n",
    "\n",
    "2. **BERTScore F1**:\n",
    "   - Measures semantic similarity between translations and references\n",
    "   - Higher scores indicate better meaning preservation\n",
    "   - Already on a 0-1 scale\n",
    "\n",
    "The comparison reveals:\n",
    "- Which model performs best according to each metric\n",
    "- How the models differ in terms of word-level accuracy vs. semantic accuracy\n",
    "- The relative strengths and weaknesses of each model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
